{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4dd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle as pkl\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f35e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTS_PATH = Path(\"../results\") / \"plots\"\n",
    "PLOTS_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5af4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_json(json_path: Path, key: str) -> pd.DataFrame:\n",
    "\n",
    "    with open(json_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    key = key.split(\".\")\n",
    "    output = data\n",
    "    for el in key:\n",
    "        output = output[el]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b933a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = Path(\"../results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98edea",
   "metadata": {},
   "source": [
    "### Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = []\n",
    "for method in (RESULTS_PATH / \"synthetic\").iterdir():\n",
    "    if not method.is_dir():\n",
    "        continue\n",
    "    accuracies = [\n",
    "        get_from_json(p, \"mae_by_model\") for p in method.rglob(\"*.json\")\n",
    "    ]\n",
    "    corr_performances = [\n",
    "        get_from_json(p, \"spearmanr_corr\") for p in method.rglob(\"*.json\")\n",
    "    ]\n",
    "    results_dfs.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"problem\": [\"synthetic\"] * len(accuracies),\n",
    "                \"meta-model\": [method.stem] * len(accuracies),\n",
    "                \"mae\": accuracies,\n",
    "                \"corr\": corr_performances,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "maes = []\n",
    "for p in (RESULTS_PATH / \"synthetic\" / \"gbdsim\").iterdir():\n",
    "    maes.append(get_from_json(p / \"metrics.json\", \"mae_by_median\"))\n",
    "results_dfs.append(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"problem\": [\"synthetic\"] * len(maes),\n",
    "            \"meta-model\": [\"median\"] * len(maes),\n",
    "            \"mae\": maes,\n",
    "        }\n",
    "    )\n",
    ")\n",
    "synthetic_results_df = pd.concat(results_dfs, ignore_index=True)\n",
    "\n",
    "NAMES_MAPPING = {\n",
    "    \"gbdsim\": \"GBDSim (ours)\",\n",
    "    \"dataset2vec\": \"Dataset2Vec\",\n",
    "    \"median\": \"Median\",\n",
    "}\n",
    "\n",
    "synthetic_results_df[\"meta-model\"] = synthetic_results_df[\"meta-model\"].map(\n",
    "    NAMES_MAPPING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e46ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    synthetic_results_df, x=\"meta-model\", y=\"mae\", errorbar=\"se\", ax=ax\n",
    ")\n",
    "ax.set_ylabel(\"MAE (lower is better)\", fontsize=14)\n",
    "ax.set_xlabel(\"Meta-model\", fontsize=14)\n",
    "fig.savefig(PLOTS_PATH / \"synthetic_mae.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    synthetic_results_df.loc[~pd.isna(synthetic_results_df[\"corr\"])],\n",
    "    x=\"meta-model\",\n",
    "    y=\"corr\",\n",
    "    errorbar=\"se\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_ylabel(\"Correlation (higher is better)\", fontsize=14)\n",
    "ax.set_xlabel(\"Meta-model\", fontsize=14)\n",
    "fig.savefig(PLOTS_PATH / \"synthetic_corr.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = []\n",
    "for method in (RESULTS_PATH / \"uci\").iterdir():\n",
    "    if not method.is_dir():\n",
    "        continue\n",
    "    accuracies = [get_from_json(p, \"accuracy\") for p in method.rglob(\"*.json\")]\n",
    "    results_dfs.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"problem\": [\"uci\"] * len(accuracies),\n",
    "                \"meta-model\": [method.stem] * len(accuracies),\n",
    "                \"accuracy\": accuracies,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "uci_results_df = pd.concat(results_dfs, ignore_index=True)\n",
    "\n",
    "NAMES_MAPPING = {\n",
    "    \"gbdsim\": \"GBDSim (ours)\",\n",
    "    \"dataset2vec\": \"Dataset2Vec\",\n",
    "    \"median\": \"Median\",\n",
    "}\n",
    "\n",
    "uci_results_df[\"meta-model\"] = uci_results_df[\"meta-model\"].map(NAMES_MAPPING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d38f0",
   "metadata": {},
   "source": [
    "### UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabfbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "sns.barplot(uci_results_df, x=\"meta-model\", y=\"accuracy\", errorbar=\"se\", ax=ax)\n",
    "ax.set_ylabel(\"Accuracy (higher is better)\", fontsize=14)\n",
    "ax.set_xlabel(\"Meta-model\", fontsize=14)\n",
    "ax.set_ylim(0.0, 0.9)\n",
    "fig.savefig(PLOTS_PATH / \"uci_accuracy.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(25, 10))\n",
    "for i, method in enumerate((RESULTS_PATH / \"uci\").iterdir()):\n",
    "    indexes = []\n",
    "    fig.text(\n",
    "        -0.01,\n",
    "        0.25 + i * 0.5,\n",
    "        NAMES_MAPPING[method.stem],\n",
    "        va=\"center\",\n",
    "        rotation=\"vertical\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "    for j, result_path in enumerate(method.iterdir()):\n",
    "        with open(result_path / \"representations.pkl\", \"rb\") as file:\n",
    "            representations = torch.load(file, weights_only=False)\n",
    "        with open(result_path / \"representation_labels.pkl\", \"rb\") as file:\n",
    "            labels = pkl.load(file)\n",
    "        representations = MDS(n_components=2).fit_transform(representations)\n",
    "        sns.scatterplot(\n",
    "            x=representations[:, 0],\n",
    "            y=representations[:, 1],\n",
    "            hue=labels,\n",
    "            ax=ax[i, j],\n",
    "        )\n",
    "        if not (i == 0 and j == 0):\n",
    "            ax[i, j].get_legend().remove()\n",
    "fig.tight_layout()\n",
    "fig.savefig(PLOTS_PATH / \"uci_representations.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dfs = []\n",
    "for method in (RESULTS_PATH / \"uci\").iterdir():\n",
    "    indexes = []\n",
    "    for result_path in method.iterdir():\n",
    "        with open(result_path / \"representations.pkl\", \"rb\") as file:\n",
    "            representations = torch.load(file, weights_only=False)\n",
    "        with open(result_path / \"representation_labels.pkl\", \"rb\") as file:\n",
    "            labels = pkl.load(file)\n",
    "        clustering = KMeans(n_clusters=5, random_state=42)\n",
    "        labels = clustering.fit_predict(representations)\n",
    "        indexes.append(calinski_harabasz_score(representations, labels))\n",
    "    output_dfs.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"problem\": [\"uci\"] * len(indexes),\n",
    "                \"meta-model\": [method.stem] * len(indexes),\n",
    "                \"calinski_harabasz_score\": indexes,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "output_df = pd.concat(output_dfs, ignore_index=True)\n",
    "output_df[\"meta-model\"] = output_df[\"meta-model\"].map(NAMES_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed930297",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    output_df,\n",
    "    x=\"meta-model\",\n",
    "    y=\"calinski_harabasz_score\",\n",
    "    errorbar=\"se\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_ylabel(\"CH index (higher is better)\", fontsize=14)\n",
    "ax.set_xlabel(\"Meta-model\", fontsize=14)\n",
    "ax.set_ylim(0.0, 250.0)\n",
    "fig.savefig(PLOTS_PATH / \"uci_ch.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b0e9a",
   "metadata": {},
   "source": [
    "### TabRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f78266",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = []\n",
    "\n",
    "for method in (RESULTS_PATH / \"tabrepo\").iterdir():\n",
    "    model_corrs = [\n",
    "        get_from_json(p, \"metric_estimation_results.model_mae\")\n",
    "        for p in method.rglob(\"*.json\")\n",
    "    ]\n",
    "    results_dfs.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"problem\": [\"tabrepo\"] * len(model_corrs),\n",
    "                \"meta-model\": [method.stem] * len(model_corrs),\n",
    "                \"mae\": model_corrs,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "median_maes = [\n",
    "    get_from_json(\n",
    "        p,\n",
    "        \"metric_estimation_results.model_mae\",\n",
    "    )\n",
    "    for p in (RESULTS_PATH / \"tabrepo\" / \"gbdsim\").rglob(\"*.json\")\n",
    "]\n",
    "\n",
    "results_dfs.append(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"problem\": [\"tabrepo\"] * len(median_maes),\n",
    "            \"meta-model\": [\"median\"] * len(median_maes),\n",
    "            \"mae\": median_maes,\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "result_df = pd.concat(results_dfs, ignore_index=True)\n",
    "result_df[\"meta-model\"] = result_df[\"meta-model\"].map(NAMES_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "sns.barplot(result_df, x=\"meta-model\", y=\"mae\", errorbar=\"se\", ax=ax)\n",
    "ax.set_ylabel(\"MAE (lower is better)\", fontsize=14)\n",
    "ax.set_xlabel(\"Meta-model\", fontsize=14)\n",
    "ax.set_ylim(0.0, 0.4)\n",
    "fig.savefig(PLOTS_PATH / \"tabrepo_mae.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21959cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = []\n",
    "\n",
    "for method in (RESULTS_PATH / \"tabrepo\").iterdir():\n",
    "    model_corrs = [\n",
    "        get_from_json(p, \"metric_estimation_results.spearmanr_corr_model\")\n",
    "        for p in method.rglob(\"*.json\")\n",
    "    ]\n",
    "    results_dfs.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"problem\": [\"tabrepo\"] * len(model_corrs),\n",
    "                \"meta-model\": [method.stem] * len(model_corrs),\n",
    "                \"corr\": model_corrs,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "result_df = pd.concat(results_dfs, ignore_index=True)\n",
    "result_df[\"meta-model\"] = result_df[\"meta-model\"].map(NAMES_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "sns.barplot(result_df, x=\"meta-model\", y=\"corr\", errorbar=\"se\", ax=ax)\n",
    "ax.set_ylabel(\"Spearmann correlation (higher is better)\", fontsize=14)\n",
    "ax.set_xlabel(\"Meta-model\", fontsize=14)\n",
    "ax.set_ylim(0.0, 0.4)\n",
    "fig.savefig(PLOTS_PATH / \"tabrepo_corr.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = []\n",
    "\n",
    "for method in (RESULTS_PATH / \"tabrepo\").iterdir():\n",
    "    for file in method.rglob(\"*.json\"):\n",
    "        results_dfs.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"problem\": [\"tabrepo\"] * 4,\n",
    "                    \"method\": [\n",
    "                        \"Landmarkers\",\n",
    "                        \"Random pipeline\",\n",
    "                        \"Best from random dataset\",\n",
    "                        \"meta-model\",\n",
    "                    ],\n",
    "                    \"avg_rank_of_selected_pipeline\": [\n",
    "                        get_from_json(\n",
    "                            file, \"pipeline_selection_results.landmarkers\"\n",
    "                        )[\"mean\"],\n",
    "                        get_from_json(\n",
    "                            file, \"pipeline_selection_results.random_pipeline\"\n",
    "                        )[\"mean\"],\n",
    "                        get_from_json(\n",
    "                            file, \"pipeline_selection_results.random_dataset\"\n",
    "                        )[\"mean\"],\n",
    "                        get_from_json(\n",
    "                            file, \"pipeline_selection_results.model_based\"\n",
    "                        )[\"mean\"],\n",
    "                    ],\n",
    "                    \"model\": [method.stem] * 4,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "result_df = pd.concat(results_dfs, ignore_index=True)\n",
    "result_df[\"model\"] = result_df[\"model\"].map(NAMES_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc[result_df.method == \"meta-model\", \"method\"] = result_df.loc[\n",
    "    result_df.method == \"meta-model\", \"model\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2258139",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(\"method\")\n",
    "output_dfs = []\n",
    "for method in result_df.method.unique():\n",
    "    if method in (\"GBDSim\", \"Dataset2Vec\"):\n",
    "        output_dfs.append(result_df.loc[result_df.method == method])\n",
    "    else:\n",
    "        output_dfs.append(result_df.loc[result_df.method == method][:5])\n",
    "output_df = pd.concat(output_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f10782",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    output_df,\n",
    "    x=\"method\",\n",
    "    y=\"avg_rank_of_selected_pipeline\",\n",
    "    errorbar=\"se\",\n",
    "    ax=ax,\n",
    "    order=[\n",
    "        \"Landmarkers\",\n",
    "        \"GBDSim (ours)\",\n",
    "        \"Dataset2Vec\",\n",
    "        \"Best from random dataset\",\n",
    "        \"Random pipeline\",\n",
    "    ],\n",
    ")\n",
    "ax.set_ylabel(\"Normalized rank (lower is better)\", fontsize=14)\n",
    "ax.set_xlabel(\"Meta-model\", fontsize=14)\n",
    "ax.set_ylim(0.0, 0.2)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "fig.savefig(PLOTS_PATH / \"tabrepo_rank.png\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
