{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09957205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ef1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from gbdsim.data.data_pairs_generator import DatasetsPairsGenerator\n",
    "from pathlib import Path\n",
    "import json\n",
    "import tqdm\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "pl.seed_everything(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd96db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"results/uci/gbdsim/2025_04_13__17_31_46/final_model.pkl\", \"rb\"\n",
    ") as f:\n",
    "    model = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65edabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/uci/meta_split.json\", \"r\") as f:\n",
    "    meta_split = json.load(f)\n",
    "\n",
    "val_paths_with_data = list(\n",
    "    filter(\n",
    "        lambda p: p.stem in meta_split[\"val\"],\n",
    "        Path(\"data/uci/raw\").iterdir(),\n",
    "    )\n",
    ")\n",
    "\n",
    "observations = [\n",
    "    DatasetsPairsGenerator.from_paths(\n",
    "        val_paths_with_data\n",
    "    ).generate_pair_of_datasets_with_label(return_datasets_paths=True)\n",
    "    for _ in tqdm.trange(1000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    probabilities = [\n",
    "        model.model.calculate_dataset_origin_probability(\n",
    "            obs[0].cuda(),\n",
    "            obs[1].cuda(),\n",
    "            obs[2].cuda(),\n",
    "            obs[3].cuda(),\n",
    "        )\n",
    "        for obs in tqdm.tqdm(observations)\n",
    "    ]\n",
    "probabilities = torch.concat(probabilities, dim=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4fc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (probabilities > 0.5).astype(int)\n",
    "labels = np.array([obs[4] for obs in observations])\n",
    "dataset_names = [(obs[5].stem, obs[6].stem) for obs in observations]\n",
    "datasets = [obs[:4] for obs in observations]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e7369",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d2333",
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassified_idx = np.where(predictions != labels)[0]\n",
    "properly_classified_idx = np.where(predictions == labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassified_dataset_pairs = [\n",
    "    dataset_names[idx] for idx in missclassified_idx\n",
    "]\n",
    "missclassified_pairs_where_labels_are_different = [\n",
    "    pair for pair in missclassified_dataset_pairs if pair[0] != pair[1]\n",
    "]\n",
    "missclassified_pairs_where_labels_are_same = [\n",
    "    pair for pair in missclassified_dataset_pairs if pair[0] == pair[1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7724f1c",
   "metadata": {},
   "source": [
    "#### Most problematic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(\n",
    "    list(chain(*missclassified_pairs_where_labels_are_different))\n",
    ").most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd341cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(list(chain(*missclassified_pairs_where_labels_are_same))).most_common(\n",
    "    30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d2945",
   "metadata": {},
   "source": [
    "#### Dimension difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassified_dataset_pairs = [datasets[idx] for idx in missclassified_idx]\n",
    "row_count_ratios = [\n",
    "    max(\n",
    "        dataset[0].shape[0] / dataset[2].shape[0],\n",
    "        dataset[2].shape[0] / dataset[0].shape[0],\n",
    "    )\n",
    "    for dataset in missclassified_dataset_pairs\n",
    "]\n",
    "np.mean(row_count_ratios), np.std(row_count_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "properly_classified_dataset_pairs = [\n",
    "    datasets[idx] for idx in properly_classified_idx\n",
    "]\n",
    "row_count_ratios = [\n",
    "    max(\n",
    "        dataset[0].shape[0] / dataset[2].shape[0],\n",
    "        dataset[2].shape[0] / dataset[0].shape[0],\n",
    "    )\n",
    "    for dataset in properly_classified_dataset_pairs\n",
    "]\n",
    "np.mean(row_count_ratios), np.std(row_count_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9f801",
   "metadata": {},
   "source": [
    "#### Statistics difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebdcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassified_dataset_pairs = [datasets[idx] for idx in missclassified_idx]\n",
    "means = [\n",
    "    max(\n",
    "        dataset[0].mean() / (dataset[2].mean() + 1e-2),\n",
    "        dataset[2].mean() / (dataset[0].mean() + 1e-2),\n",
    "    )\n",
    "    for dataset in missclassified_dataset_pairs\n",
    "]\n",
    "np.mean(means), np.std(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "properly_classified_dataset_pairs = [\n",
    "    datasets[idx] for idx in properly_classified_idx\n",
    "]\n",
    "means = [\n",
    "    max(\n",
    "        dataset[0].mean() / (dataset[2].mean() + 1e-2),\n",
    "        dataset[2].mean() / (dataset[0].mean() + 1e-2),\n",
    "    )\n",
    "    for dataset in properly_classified_dataset_pairs\n",
    "]\n",
    "np.mean(means), np.std(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeba04d",
   "metadata": {},
   "source": [
    "#### Priors difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassified_dataset_pairs = [datasets[idx] for idx in missclassified_idx]\n",
    "means = [\n",
    "    max(\n",
    "        dataset[1].mean() / (dataset[3].mean() + 1e-2),\n",
    "        dataset[3].mean() / (dataset[1].mean() + 1e-2),\n",
    "    )\n",
    "    for dataset in missclassified_dataset_pairs\n",
    "]\n",
    "np.mean(means), np.std(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123cf62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "properly_classified_dataset_pairs = [\n",
    "    datasets[idx] for idx in properly_classified_idx\n",
    "]\n",
    "means = [\n",
    "    max(\n",
    "        dataset[1].mean() / (dataset[3].mean() + 1e-2),\n",
    "        dataset[3].mean() / (dataset[1].mean() + 1e-2),\n",
    "    )\n",
    "    for dataset in properly_classified_dataset_pairs\n",
    "]\n",
    "np.mean(means), np.std(means)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
